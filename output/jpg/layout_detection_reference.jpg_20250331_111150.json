{
  "original_file": "d:\\project\\data_clean\\input\\layout_detection_reference.jpg",
  "processed_time": "20250331_111150",
  "documents": [
    {
      "content": "```html\n<html><body>\n<div class=\"image\"><img/></div> \n <p>(a) Main Page Annotation Example 1</p> \n <div class=\"image\"><img/></div> \n <p>(b) Main Page Annotation Example 2</p> \n <div class=\"image\"><img/></div> \n <p>(c) Index Page Annotation Example</p> \n <p>Page Frame Row Text Region Title Region Title Subtitle Other</p> \n <p>Figure 7: Annotation Examples in HJDataset. (a) and (b) show two examples for the labeling of main pages. The boxes are colored differently to reflect the layout element categories. Illustrated in Â©, the items in each index page row are categorized as title blocks, and the annotations are denser.</p> \n <p>tion over union (IOU) level $[0.50: 0.95]^{2}$, on the test data. In general, the high mAP values indicate accurate detection of the layout elements. The Faster R-CNN and Mask R-CNN achieve comparable results, better than RetinaNet. Noticeably, the detections for small blocks like title are less precise, and the accuracy drops sharply for the title category. In Figure 8, (a) and (b) illustrate the accurate prediction results of the Faster R-CNN model.</p> \n <h3> 5.2. Pre-training for other datasets</h3> \n <p>We also examine how our dataset can help with a real-world document digitization application. When digitizing new publications, researchers usually do not generate large scale ground truth data to train their layout analysis models. If they are able to adapt our dataset, or models trained on our dataset, to develop models on their data, they can build their pipelines more efficiently and develop more accurate models. To this end, we conduct two experiments. First we examine how layout analysis models trained on the main pages can be used for understanding index pages. Moreover, we study how the pre-trained models perform on other historical Japanese documents.</p> \n <p>Table 4 compares the performance of five Faster R-CNN models that are trained differently on index pages. If the model loads pre-trained weights from HJDataset, it includes information learned from main pages. Models trained over</p> \n <hr/> \n <section class=\"footnotes\"><ol class=\"footnotes-list\"><li class=\"footnote-item\"><p>$^{2}$ This is a core metric developed for the COCO competition [12] for evaluating the object detection quality.</p></li></ol></section> \n <p>all the training data can be viewed as the benchmarks, while training with few samples (five in this case) are considered to mimic real-world scenarios. Given different training data, models pre-trained on HJDataset perform significantly better than those initialized with COCO weights. Intuitively, models trained on more data perform better than those with fewer samples. We also directly use the model trained on main to predict index pages without fine-tuning. The low zero-shot prediction accuracy indicates the dissimilarity between index and main pages. The large increase in mAP from 0.344 to 0.471 after the model is</p> \n <p>Table 3: Detection mAP @ IOU $[0.50: 0.95]$ of different models for each category on the test set. All values are given as percentages.</p> \n <div class=\"table\" style=\"text-align: center\"><table><tbody><tr><td style=\"text-align: left\">Category</td><td style=\"text-align: left\">Faster R-CNN</td><td style=\"text-align: left\">Mask R-CNN ${ }^{\\mathrm{a}}$</td><td style=\"text-align: left\">RetinaNet</td></tr><tr><td style=\"text-align: left\">Page Frame</td><td style=\"text-align: left\">99.046</td><td style=\"text-align: left\">99.097</td><td style=\"text-align: left\">99.038</td></tr><tr><td style=\"text-align: left\">Row</td><td style=\"text-align: left\">98.831</td><td style=\"text-align: left\">98.482</td><td style=\"text-align: left\">95.067</td></tr><tr><td style=\"text-align: left\">Title Region</td><td style=\"text-align: left\">87.571</td><td style=\"text-align: left\">89.483</td><td style=\"text-align: left\">69.593</td></tr><tr><td style=\"text-align: left\">Text Region</td><td style=\"text-align: left\">94.463</td><td style=\"text-align: left\">86.798</td><td style=\"text-align: left\">89.531</td></tr><tr><td style=\"text-align: left\">Title</td><td style=\"text-align: left\">65.908</td><td style=\"text-align: left\">71.517</td><td style=\"text-align: left\">72.566</td></tr><tr><td style=\"text-align: left\">Subtitle</td><td style=\"text-align: left\">84.093</td><td style=\"text-align: left\">84.174</td><td style=\"text-align: left\">85.865</td></tr><tr><td style=\"text-align: left\">Other</td><td style=\"text-align: left\">44.023</td><td style=\"text-align: left\">39.849</td><td style=\"text-align: left\">14.371</td></tr><tr><td style=\"text-align: left\">mAP</td><td style=\"text-align: left\">81.991</td><td style=\"text-align: left\">81.343</td><td style=\"text-align: left\">75.223</td></tr></tbody></table></div> \n <hr/><section class=\"footnotes\"><ol class=\"footnotes-list\"><li class=\"footnote-item\"><p>${ }^{a}$ For training Mask R-CNN, the segmentation masks are the quadrilateral regions for each block. Compared to the rectangular bounding boxes, they delineate the text region more accurately.</p></li></ol></section> \n</body></html>\n```",
      "metadata": {
        "source": "d:\\project\\data_clean\\input\\layout_detection_reference.jpg",
        "processor": "qwen-vl-ocr"
      }
    }
  ]
}